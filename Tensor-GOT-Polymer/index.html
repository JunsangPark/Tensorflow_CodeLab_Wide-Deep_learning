
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, user-scalable=yes">
    <!-- REMOVE THIS METATAG on public launch! -->
    <meta name="robots" content="noindex">

    <title>Wide+Deep learning tutorial with TensorFlow and Game of Thrones</title>
    <meta name="description" content="who-will-die-got-tensorflow-codelab description">

    <!-- See https://goo.gl/OOhYW5 -->
    <link rel="manifest" href="/manifest.json">

    <script src="/bower_components/webcomponentsjs/webcomponents-lite.js"></script>

    <link rel="import" href="/bower_components/codelab-components/google-codelab-elements.html">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
    <style>
      body {
        font-family: "Roboto",sans-serif;
        background-color: #e0e0e0;
      }
    </style>
  </head>
  <body>

  <google-codelab 
      title="Discover what GOT Character will die next with TensorFlow"
      environment="web"
      feedback-link="https://github.com/codelab-tf-got/codelab-tf-got.github.io/issues"
      last-updated="2016-12-01">

    <!-- STEP 1 -->
    <google-codelab-step 
      label="Presentation" 
      step="1" 
      duration="5">
      <p>

      
      <img src="0_logo.png" alt="TensorFlow Game of Thrones"> 
             <a href="http://tensorflow.org/" target="_blank" rel="noopener">TensorFlow</a> is a an open source library for numerical computation, specializing in machine learning applications. In this codelab, you will learn how to install and run TensorFlow on a single machine, and will predict deaths on Game of Thrones data using the tutorial Wide+Deep Learning Network.</p>
      <h2>What are we going to be building?</h2>
      <p>
      This codelab presents wide+deep learning model execution taking into account Game of Thrones data for Death classification & prediction .
The aim of this Codelab is to dig into wide+deep neural network model  to combine the benefits of memorization+generalization models, in which wide model is directly relevant to features and deep model improves the diversity of recommended systems. 

	The wide+deep learning tutorial comes within census data so we have been working with an analogous dataset taking into consideration Game of Thrones .</p>
      <h2 class="checklist">What You&#39;ll Learn</h2>
      <p>
      In the next sections you will know  how the dataset works ,how to implement the wide+deep learning model  and finally some conclusions about the experimentation with the model, and more in detail . Besides and listed, you will learn how to:</p> 
      <ul class="checklist">
        <li>Familiarize yourself with Tensorflow  </li>
        <li>How to select features for the wide part: choose the sparse base columns and crossed columns you want to use.</li>
        <li>Select features for the deep part: choose the continuous columns, the embedding dimension for each categorical column, and the hidden layer sizes.</li>
        <li>How to design the Wide+Deep Learning TensorFlow model </li>
        <li>Put them all together in a Wide & Deep model (DNNLinearCombinedClassifier).</li>
      </ul>

      <h2 class="checklist">What You&#39;ll Need</h2>
      <ul>
        <li>A computer connected to the internet with Python2.7 installed </li>
        <li>The libraries sklearn, pandas , numpy installed </li>
        <li>A basic understanding of python and neural nets</li>
        <li>A fast computer running OS X or Linux</li>
        <li>A fair amount of time</li>
      </ul>
	    
          <h2 class="checklist">The Goal</h2>
      <ul>
        <li>To made a classification model </li>
        <li>Predict the next character death probability in Game of Thrones</li>
      </ul>

      <aside class="special">
        <p>
        <strong>Note:</strong>  This codelab has quiet periods of downloading and training. During those times, it might be a fun idea to play with the <a href="http://playground.tensorflow.org/" target="_blank" rel="noopener">TensorFlow Playground to learn more about neural net design</a>
        </p>
      </aside>

    </google-codelab-step>
    <google-codelab-step> 
      label="Visualization behind GoT DataSet" 
      step="2" 
      duration="10">
      <p>
      <h2>The data powering the CodeLab</h2>
      <img src="1_Comic.png" alt="TensorFlow JohnSnow & Sam correlation"> 
      <p>
      The GoT dataset was compiled from a <a href="https://www.kaggle.com/" target="_blank" rel="noopener">kaggle</a> dataset and transformed to offer more information using Game of Thrones wiki . 
      Before going into a deeper data analysis, we would like to offer a view about the power of search with Answer the public tool. Using this visualization about the main five W some questions could be underlined about game of Thrones using  the searches in US and UK 
      These visualization flashlights the public interest about Game of Thrones deaths related to Why,What,When and How. In most of the searches there comes an interest about why all characters die, in which book each character die or in which TV season as well as searches about video compilations . Also we might  find comparisons to Walking Death. In a first general approach, we can see that searches about Game of Thrones Deaths are related to which deaths are packaged in each book or season. 
      The question ‘how’ might offer us a more practical approach about  people searching for compilation of deaths, Youtube videos about it. </p>
      <img src="2_question-visualisation.gif" alt="The five 5`ws about searches in Game of Thrones">     
      <h2>Data analysis</h2>
      <p>
	During this 0 point  we will serve as company for Tensorflow Codelab based on Game of Thrones Data, in order to provide a Neural Network model to classify the probability of Death of Game of Thrones characters with wide+deep model .
There is some data theory we will dive in when implementing the model, but first we will dig a little bit in the data in order to know more about the behaviour of our dataset </p>
      <p>
####--------------------------COMPONENT BUTTON -------------------------------######
You can download the data from the button below. The original dataset has been released in Kaggle and we have been filling the information in Game of Thrones wiki focusing on title, culture . </p>
      <p>
####--------------------------COMPONENT TABLE --------------------------------#####
   
In one first approach of the dataset we extract the following useful information about the dataset, wich we consider a significant first approach for finding correlations and relationships in between variables 
	NUMBER OF CHARACTERS :  1946
	MEDIAN OF  AGE : 27
	      CORRELATION BETWEEN Number of Death Relationships and Popularity : 0.663 </p>
      <P>
	Here we have some graphics that show correlation among data , having into account that most of them show relationships in between popularity and other characteristics .
      <img src="1_CultureGOT.png" alt="Culture Analysis">  Game of Thrones character ecosystem shows a diverse culture approach that prints a diverse atmosphere , without a doubt it really brings to the table a rich atmosphere to enjoy. Among all cultures, the most significant are Valyrian - as House Targaryen members- , Northmen -like watchmen -that has the highest value in culture with 143 characters,  and Andals - like House Lannister. 
      <img src="_________.png" alt="Histogram of popularity">On this first approach of Histogram of popularity , more than 750 characters , about 40 % are ranged with 0 popularity ; being the most popular character listed – less than 20 , about a 1.02 % - the following, described together within .
However, the median of popularity is 0.03344
	Below we show a comparative table in between the top 10 popular characters and the top 10 probability likelihood of Death, can you find any relationship in between it? 
As a comparative conclusion, we might underline the popularity of Baratheons and Starks and their absence from the high probability of death and the amounts of Targaryens that seems to be related with life ending situations.
####--------------------------COMPONENT TABLE --------------------------------#####
Baratheons are among the most popular and also far away from the most probability of death
      <p>
 <img src="3_TensorflowDPr.gif" alt="Popularity VS number of Death Relations">
With this graph we would like to enlighten us to solve the following questions
Is there a relationship in between the popularity of a character and the number of death Characters?
As you can see the popularity listed as 1 there is a constant interval that goes from 1 to 10 deaths. Also there is presence in more than 15 deaths

On the Y axis we can find a score that goes from 0 to 1 and gives us an idea of the popularity of the current character and scored on the X axis the number of death relationships that go from 0 to 14. The visualization of this graph drops some conclusions upon us :
    0) Most popularity characters are ranked from 0 to 0.6 and have 0 dead relationships .
Very popular characters -ranked as 1-  have an extrange +
    1) We could draw an exponential classify curve that give us a certain pattern and given the following conclusions .
--Most of unpopular characters have  no dead relationships
–There is a linear incremental number of dead relationships once the character is very popular 
--A  very popular character with a high number of dead relations can be considered an outlier . 
     </p>
     <h2>"Once you are very popular, there 're seems to be a linear incremental pattern of Death Relationship</h2>
     <p>As we dig into the data, so do we within the question we actually want to solve . How is popularity related to Death in Game of Thrones. </p>
     <img src="_________.gif" alt="you know nothing sql">
     <p>This first approach has been great ! No let´s move into installing Tensorflow and have a deeper understanding with wide+deep learning model to gain more knowledge  . </p>
    <!-- STEP 3 -->
    <google-codelab-step>  
      label="Installing Tensorflow V1" 
      step="1" 
      duration="10">
      <p>
      <h2>Instalation of Tensorflow</h2>
      <p>Follow installation instructions for the following platforms </p>
	    <p>Linux</p> <a href="https://www.tensorflow.org/install/install_linux" target="_blank" rel="noopener">linux</a>
	    <p>Mac</p> <a href="https://www.tensorflow.org/install/install_mac" target="_blank" rel="noopener">Mac</a>
	    <p>Windows</p> <a href="https://www.tensorflow.org/install/install_windows" target="_blank" rel="noopener">Windows</a>
	    <p>From Source</p> <a href="https://www.tensorflow.org/install/install_sources" target="_blank" rel="noopener">From Source</a>
      <p>Here we cover Linux installation but you can see different . So , since the v1 release, you can type </p>
      <pre><code>
$ pip install tensorflow      # Python 2.7; CPU support (no GPU support)
 $ pip3 install tensorflow     # Python 3.n; CPU support (no GPU support)
 $ pip install tensorflow-gpu  # Python 2.7;  GPU support
 $ pip3 install tensorflow-gpu # Python 3.n; GPU support
      </code></pre>
	    <p>Great! Now you should have your instalation complete. You can test in your console typing in python</p>
	    <p>>>> import tensrflow</p>
    </google-codelab-step>	    
    <google-codelab-step>  
      label="Downloading the CodeLab" 
      step="4" 
      duration="10">
      <p>
      <h2>Downloading the CodeLab</h2>	
      <p>You can download the code and the data below. We suggest you to download both and put them in the same folder .  We will be explaining afterwards in each model which part of the codes matches with each part of wide + deep learning model . 
    Once you have it downloaded into your computer, you can play with it . </p>
      <h2>CodeLab Structure</h2>		    
     <img src="_________.jpg" alt="folder"> <p> Download the code and the data_set and put it on a folder. It should contain the file wide+deep_Tensorflow_GOT and the file GOT_data.csv </p>
     <img src="_________.jpg" alt="data search"> <p>      Open the file and change the path in your dataset :
	    									  data_set = ‘your_path_here’</p>
     <img src="_________.jpg" alt="console"> <p>In console, execute the program  : 
	                                                                          ~ $ python 'program'</p>
     <img src="_________.jpg" alt="console"> <p>In console, execute Tensorflow  : 
	                                                                          ~ $ tensorboard --logdir =/tmp/model/</p>
    </google-codelab-step>	   
    <google-codelab-step>  
      label="Network Structure" 
      step="5" 
      duration="10">
      <p>
      <h2>Network Structure</h2>
      <p>During the next session we will explain the architecture of the Wid+Deep learning model having into consideration the published paper by Google. We also recommend the talk given by Heng-Tze Cheng at Tensorflow Dev Summit 2017 . </p> 
      <p>The aim of this model is to combine the benefits of memorization+generalization models, in wich wide model is directly relevant to features and deep model improves the diversity of recommended systems. 
      The abstraction of concepts in this text comes from the paper wide + deep learning for recommender systems </p>  <a href="https://arxiv.org/pdf/1606.07792.pdf" target="_blank" rel="noopener">Paper here!</a>
      <p>With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize
and recommend less relevant items when the user-item interactions are sparse and high-rank. 
Wide+Deep learning combines the benefits the Memorization and generalization , which is a current challenge for learning systems. Each part of the nets shows it challenges as well, so in Wide net we can find crossed columns and in deep learning we can find embeddings as the most significant concepts operating in each part of the Network . </p>
      <h2>Network Structure</h2>    
      <p> During the next session we will explain the architecture of the Wid+Deep learning model having into consideration the published paper by Google. We also recommend the <a href="https://www.youtube.com/watch?v=NV1tkZ9Lq48&list=PLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv&index=17" target="_blank" rel="noopener">talk</a> given by Heng-Tze Cheng at Tensorflow Dev Summit 2017 . </p>
      <img src="_________.gif" alt="network">    				     
      <p> The aim of this model is to combine the benefits of memorization+generalization models, in wich wide model is directly relevant to features and deep model improves the diversity of recommended systems. 
The abstraction of concepts in this text comes from the paper wide + deep learning for recommender systems  <a href="https://arxiv.org/pdf/1606.07792.pdf" target="_blank" rel="noopener">paper</a></p>	    
      <p>With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize
and recommend less relevant items when the user-item interactions are sparse and high-rank. 
Wide+Deep learning combines the benefits the Memorization and generalization , which is a current challenge for learning systems. Each part of the nets shows it challenges as well, so in Wide net we can find crossed columns and in deep learning we can find embeddings as the most significant concepts operating in each part of the Network . </p>
      <img src="_________.jpg" alt="meme_Stark">
      <h2>Base Features</h2>
      <p>Categorical variables are also known as discrete or qualitative variables. Categorical variables can be further categorized as either nominal, ordinal or dichotomous. Nominal variables are variables that have two or more categories, but which do not have an intrinsic order.
Continuos variables are those that refers to continuous values such as numbers </p> 
      <pre><code>
CATEGORICAL_COLUMNS = ["alive", "title", "male", "culture",
                       "house", "spouse", "isAliveMother", "isAliveFather", "isAliveHeir",
                       "isAliveSpouse", "isMarried", "isNoble", "numDeadRelations",
                       "boolDeadRelations", "isPopular" , "popularity"]

CONTINUOUS_COLUMNS = ["name", "dateOfBirth",  "mother", "father",
                      "heir", "book1", "book2", "book3", "book4", "book5", "age",
                      "isAlive", "house", "title", "numDeadRelations"]
      </code></pre>
      <h2>Linear classiffier: Memorization</h2>	
      <p>Memorization -Wide Model- Comes with learning the frequent co-ocurrence of features and exploiting the correlation available in the historical data. It is directly relevant to features . It can be achieved effectively using cross-product transformations over sparse features. Memorization is directly relevant to features. 
The linear classifier digs into continuous features . In a practical approach you could say that this model is suitable for continuous -often numerical data- which already can be made some sense of. This model needs manual feature engineering for crossed relationships between columns. 
Beyond you can find how we approach the linear classifier in the exercise :
We define the linear variables in the columns
We execute the linear classifier 

Here the design of the net comes with the combination of features that can combine the information in order to offer a suitable conclusion </p> 
      <img src="_________.jpg" alt="crossing_narrow_sea">    
      <pre><code>
      # Wide columns and deep columns.
wide_columns = [name, dateOfBirth, DateoFdeath, mother, father, heir, book1, book2,
                book3, book4, book5, age, isAlive
                tf.contrib.layers.crossed_column([house, title],
                                                 hash_bucket_size=int(1e4)),
                tf.contrib.layers.crossed_column(
                    [age_buckets, house, title],
                    hash_bucket_size=int(1e6)),
                tf.contrib.layers.crossed_column([numDeadRelations, title],
                                                 hash_bucket_size=int(1e4))]
      </code></pre> 
      <h2>Deep layer</h2>
      <img src="_________.gif" alt="netkork">
      <p>Generalization - Deep Model-  the model is a Feedfoward neural network that works with categorical features . there exist Transitivity of correlation and explores feature combinations that have never or rarely occurred in the past. It improves the diversity of recommended items . This generalization can be added by using features that are less granular . 
So at the end this model is great for combining two different models of classification using neural Networks. You can see how this model has been working with </p> 
      <h2>Deep layer</h2>  
      <p>Embeddings are mathematical abstractions of categorical data. Their main purpose is to find relationships in between the data and show them in a 3 dimensional space.
Tensorflow has released its own playground for embeddings using words and image data . You can find it here . </p>
      <pre><code>
	  deep_columns = [
      tf.contrib.layers.embedding_column(title, dimension=8),
      tf.contrib.layers.embedding_column(house, dimension=8),
      tf.contrib.layers.embedding_column(culture, dimension=8),
      tf.contrib.layers.embedding_column(isAliveNoble, dimension=8),
      tf.contrib.layers.embedding_column(numberDeadRelations,
                                         dimension=8),
      tf.contrib.layers.embedding_column(popularity, dimension=8),
      male,
      spouse,
      isPopular,
      spouse,
      isMarried,
  ]  
       </code></pre> 
      <h2>Combining wide and deep learning model into one</h2>	    
      <p>The wide models and deep models are combined by summing up their final output log odds as the prediction, then feeding the prediction to a logistic loss function. All the graph definition and variable allocations have already been handled for you under the hood, so you simply need to create a DNNLinearCombinedClassifier: </p>
      <pre><code>
      import tempfile
model_dir = tempfile.mkdtemp()
m = tf.contrib.learn.DNNLinearCombinedClassifier(
    model_dir=model_dir,
    linear_feature_columns=wide_columns,
    dnn_feature_columns=deep_columns,
    dnn_hidden_units=[100, 50])      
      </code></pre>
      <h2>Optimizers</h2>
      <img src="_________.jpg" alt="cercei_queen">
      <p>The Optimizer base class provides methods to compute gradients for a loss and apply gradients to variables. A collection of subclasses implement classic optimization algorithms such as GradientDescent and Adagrad.
Optimizers are a detailed part of neural net design that can offer a real performance difference among the neural net models. You can find  documentation about Tensorflow optimizers <a href="https://www.tensorflow.org/api_guides/python/train" target="_blank" rel="noopener">here</a>
If we had to underline a concept about optimizers it would be the learning_rate .We could define the learning_rate as a value used by the learning algorithm to determine how quickly the weights are adjusted. It determines the adquisition time for neurons with weights that are trained using the algortihm.
	Bellow we describe the parameters and the main characteristics of the optimizers wich you can try in the model. Note that the model has been defined as bellow and optimizers have been changed for that model : </p>
####--------------------------COMPONENT TABLE -------------------------------######
      <h2>Comparison</h2>
      <p></p>
